{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyMCI91HlYKGggwkk5FsUMj7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **2023년 동계 영재교육 담당교원 기초과정 직무연수**\n","\n","**제4차 산업혁명의 핵심: 융합시대의 빅데이터 및 빅데이터 활용법 (2023년 1월 11일)**\n","\n","## **토픽 모델링 실습**"],"metadata":{"id":"5xmEUlIo1D2O"}},{"cell_type":"markdown","source":["# **한국어 표시(display)를 위한 사전 세팅**"],"metadata":{"id":"W9rY-FmwdIOy"}},{"cell_type":"code","source":["!apt -qq -y install fonts-nanum # 나눔폰트를 설치"],"metadata":{"id":"LedPWCjbdIdA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.font_manager as fm\n","import matplotlib.pyplot as plt # 시각화를 위한 라이브러리\n","sys_font=fm.findSystemFonts()\n","nanum_font = [f for f in sys_font if 'Nanum' in f]\n","print(f\"nanum_font number: {len(nanum_font)}\")\n","print(nanum_font)\n","# 설치된 나눔 폰트 종류 확인\n","# 나눔 바른 고딕을 사용할 예정"],"metadata":{"id":"zYhJyVfCdZvn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["path = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf' \n","font_name = fm.FontProperties(fname=path, size=10).get_name()\n","print(font_name)\n","plt.rc('font', family=font_name)\n","fm._rebuild()"],"metadata":{"id":"dv9PnkI5defp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 형태소 분석을 위해 한글 분석 모듈 konlpy를 설치\n","# 형태소: 단어의 최소단위, 언어학에서 일정한 의미가 있는 가장 작은 말의 단위\n","# 참조: https://konlpy.org/ko/latest/index.html\n","!pip install konlpy"],"metadata":{"id":"M3UOy4bmdh-n"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **한국어 전처리를 위한 KoNLPy 설치**"],"metadata":{"id":"y3hDZu6qx1-I"}},{"cell_type":"code","source":["import konlpy \n","print('KoNLPy version...:', konlpy.__version__)"],"metadata":{"id":"KMLvd7vkjuQp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from konlpy.tag import Okt\n","okt = Okt()\n","okt.pos('토픽모델링을 활용한 국내 문헌정보학 연구동향 분석')"],"metadata":{"id":"s31aG_2LxRsl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["konlpy.data.path"],"metadata":{"id":"IejMEPCAuPD3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cd /usr/local/lib/python3.8/dist-packages/konlpy/java"],"metadata":{"id":"zFNIzIcQufpX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ls"],"metadata":{"id":"4iYNOYzpulbu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","os.chdir('/usr/local/lib/python3.8/dist-packages/konlpy/java')\n","os.getcwd() "],"metadata":{"id":"XolH0t3Iurch"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["os.makedirs('./aaa') # 임시 폴더를 생성"],"metadata":{"id":"zFcO-X6ru_4s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["os.chdir('/usr/local/lib/python3.8/dist-packages/konlpy/java/aaa')"],"metadata":{"id":"f9Ml_zS2wiCD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!jar xvf ../open-korean-text-2.1.0.jar"],"metadata":{"id":"Vq4yqfxcvruz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 사용자 사전 열기\n","with open(f\"/usr/local/lib/python3.8/dist-packages/konlpy/java/aaa/org/openkoreantext/processor/util/noun/nouns.txt\") as f:\n","    data = f.read()"],"metadata":{"id":"I5-EgZ99wvDe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data[:5]"],"metadata":{"id":"SddErXDmvuNf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 새로운 단어 추가\n","data += '토픽모델링\\n연구동향\\n'"],"metadata":{"id":"h3Djuxz2xKmM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 파일 새롭게 저장\n","with open(f\"/usr/local/lib/python3.8/dist-packages/konlpy/java/aaa/org/openkoreantext/processor/util/noun/nouns.txt\", 'w') as f:\n","    f.write(data)"],"metadata":{"id":"puG9smT-xboj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!jar cvf ../open-korean-text-2.1.0.jar * # 다시 압축해주는 과정"],"metadata":{"id":"mEvmwTZvxg4M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from konlpy.tag import Okt\n","okt = Okt()\n","okt.pos('토픽모델링을 활용한 국내 문헌정보학 연구동향 분석')"],"metadata":{"id":"smDjtRI1xkea"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **커스텀하게 단어(명사)를 새롭게 등록하게 해주는 라이브러리 설치**"],"metadata":{"id":"jI5qra5VryUH"}},{"cell_type":"code","source":["!pip install customized-KoNLPy"],"metadata":{"id":"T6uH88fyrmhu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from konlpy.tag import Okt\n","okt = Okt()\n","okt.pos('토픽모델링을 활용한 국내 문헌정보학 연구동향 분석')"],"metadata":{"id":"QCqW0dvdsLAU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from ckonlpy.tag import Twitter\n","twitter = Twitter()\n","twitter.add_dictionary('토픽모델링', 'Noun') # 커스텀하게 단어(명사)추가가 가능\n","twitter.add_dictionary('연구동향', 'Noun')\n","twitter.pos('토픽모델링을 활용한 국내 문헌정보학 연구동향 분석')"],"metadata":{"id":"-1ZCA_kS1zMs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Mecab 모듈 다루기 (고급버전)**"],"metadata":{"id":"_ybLNeCapYVv"}},{"cell_type":"code","source":["# 형태소 분석을 위해 한글 분석 모듈 Mecab 설치\n","# 참조: https://github.com/SOMJANG/Mecab-ko-for-Google-Colab\n","! git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git"],"metadata":{"id":"0qIPaM4CgXEi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cd Mecab-ko-for-Google-Colab/"],"metadata":{"id":"0fdL_DLGhCDh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ls"],"metadata":{"id":"-gZm7TXAk99_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!bash install_mecab-ko_on_colab190912.sh"],"metadata":{"id":"Pp1p8bTWhHrI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from konlpy.tag import Mecab\n","mecab = Mecab()\n","sentence = '이제 구글 코랩에서 Mecab 라이브러리의 사용이 가능합니다. 읽어주셔서 감사합니다.'\n","nouns = mecab.nouns(sentence)\n","print(nouns)"],"metadata":{"id":"Kac7YGKGkHpv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from konlpy.tag import Mecab\n","mecab = Mecab()\n","sentence = '토픽모델링을 활용한 국내 문헌정보학 연구동향 분석'\n","nouns = mecab.nouns(sentence)\n","print(nouns)"],"metadata":{"id":"zaJ0sDNCpxEG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["✅ **몇 가지 사전 세팅이 필요**"],"metadata":{"id":"Oclk70Ijmv1F"}},{"cell_type":"markdown","source":["1) 왼쪽 폴더에서 mecab-ko-dic-2.1.1-20180720로 이동"],"metadata":{"id":"ilDWen_jm2Pr"}},{"cell_type":"code","source":["cd /content/mecab-ko-dic-2.1.1-20180720"],"metadata":{"id":"UzjoNmagmh4u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ls user-dic"],"metadata":{"id":"Enyc6Ds9nMcp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["2) user-dic 폴더를 선택\n","\n","nnp.csv 는 명사, person.csv 는 인명, place.csv 는 등록되지 않은 장소에 대한 이름을 등록하는 파일로, 새로운 명사를 해당 파일을 열어 새롭게 등록(customizing)할 수 있음."],"metadata":{"id":"MJIC_6GpoA6F"}},{"cell_type":"code","source":["with open(\"./user-dic/nnp.csv\", 'r', encoding='utf-8') as f:\n","  file_data = f.readlines()"],"metadata":{"id":"VwPEAXwmn-x1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["file_data # F와 T는 마지막 글자에 받침이 있는지 없는지 (종성여부)를 나타냄"],"metadata":{"id":"24Gr8OPloaXl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["word_list = [\"토픽모델링\", \"문헌정보학\",\"연구동향\"]"],"metadata":{"id":"gFOYqhvCpqoT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install jamo"],"metadata":{"id":"ZnZZHs3xpqk3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from jamo import h2j, j2hcj\n","def get_jongsung_TF(sample_text):\n","    sample_text_list = list(sample_text)\n","    last_word = sample_text_list[-1]\n","    last_word_jamo_list = list(j2hcj(h2j(last_word)))\n","    last_jamo = last_word_jamo_list[-1]\n","\n","    jongsung_TF = \"T\"\n","\n","    if last_jamo in ['ㅏ', 'ㅑ', 'ㅓ', 'ㅕ', 'ㅗ', 'ㅛ', 'ㅜ', 'ㅠ', 'ㅡ', 'ㅣ', 'ㅘ', 'ㅚ', 'ㅙ', 'ㅝ', 'ㅞ', 'ㅢ', 'ㅐ,ㅔ', 'ㅟ', 'ㅖ', 'ㅒ']:\n","        jongsung_TF = \"F\"\n","\n","    return jongsung_TF"],"metadata":{"id":"dxPeyOdeqhPl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open(\"./user-dic/nnp.csv\", 'r', encoding='utf-8') as f:\n","  file_data = f.readlines()\n","\n","for word in word_list:\n","  jongsung_TF = get_jongsung_TF(word)\n","\n","  line = '{},,,,NNP,*,{},{},*,*,*,*,*\\n'.format(word, jongsung_TF, word)\n","\n","  file_data.append(line)"],"metadata":{"id":"ayhe30yxqtyO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["3) 단어를 새롭게 추가 후 저장하는 과정"],"metadata":{"id":"3fwONi6QrBPd"}},{"cell_type":"code","source":["with open(\"./user-dic/nnp.csv\", 'w', encoding='utf-8') as f:\n","  for line in file_data:\n","    f.write(line)"],"metadata":{"id":"jl-7mnsjocdb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open(\"./user-dic/nnp.csv\", 'r', encoding='utf-8') as f:\n","  file_new = f.readlines()\n","file_new"],"metadata":{"id":"stmPyypiq_hv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ls"],"metadata":{"id":"0vaibrknrIe9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ls tools"],"metadata":{"id":"p5pQIt8YrLwx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["4) tools 디렉토리\n","\n","tools 디렉토리가 있다면 tools 디렉토리 안에 add-userdic.sh* 라는 쉘스크립트가 있는지 확인"],"metadata":{"id":"cTMl-l_qrSJM"}},{"cell_type":"code","source":["!bash ./tools/add-userdic.sh"],"metadata":{"id":"BqPrnD3_rOAg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!make install"],"metadata":{"id":"yJDyHh32rVCP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from konlpy.tag import Mecab\n","mecab = Mecab()\n","sentence = '토픽모델링을 활용한 국내 문헌정보학 연구동향 분석'\n","nouns = mecab.nouns(sentence)\n","print(nouns)"],"metadata":{"id":"P_UmeoOWrZL0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # 형태소 분석을 위해 한글 분석 모듈 Mecab 설치.\n","# 혹시 위의 설치 방법이 오류가 나는 경우 활용.\n","# # 다른 모듈/라이브러리의 설치와 달리 약간의 시간이 걸리는 작업.\n","# !bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)"],"metadata":{"id":"DyS_RBIveL-k"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["🏃 **런타임 재시작 필요**"],"metadata":{"id":"RUQipOxflc2P"}},{"cell_type":"code","source":["# 테스트를 위한 시각화 - 한글 출력이 되는지 확인\n","# 한글이 정상적으로 출력이 되는지 확인 후 진행 !\n","# 일반적을 재시작을 해주어야 함\n","plt.plot(['서울', '경기', '인천', '광주', '대구', '부산', '울산', '대전', '제주'], [12, 32, 4, 0, 5, 2, 19, 9, 3])\n","plt.xlabel('x축')\n","plt.ylabel('y축')\n","plt.show()"],"metadata":{"id":"AtdhlG_8eIiF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **데이터 불러오기**\n","\n","영화 아바타2의 네티즌 평점 및 리뷰\n"," \n","(데이터 출처: 네이버 영화)"],"metadata":{"id":"kcTmIuMR87pd"}},{"cell_type":"code","source":["import pandas as pd # 일종의 엑셀과 같은 기능을 해주는 라이브러리\n","import numpy as np \n","avatar2 = pd.read_csv(\"https://raw.githubusercontent.com/gnu-mot/tutoring/main/movie_avatar2.csv\") "],"metadata":{"id":"cvKJAlL984vW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["avatar2.head()"],"metadata":{"id":"bymKRj109pFK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["avatar2.shape"],"metadata":{"id":"rfcbeaJIaTV0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for review in avatar2['영화감상평']:\n","  if len(review) < 10: # 문장의 길이가 10 미만인 경우를 출력\n","    print(review) # 아래 리뷰들이 큰 의미가 없다고 판단되면, 제거하고 진행도 가능."],"metadata":{"id":"AtZuoit29crg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["문장의 길이가 10 미만인 경우 삭제하고 진행"],"metadata":{"id":"9GLmXGBWZPKF"}},{"cell_type":"markdown","source":["# **데이터 전처리**"],"metadata":{"id":"iFQ18mFnamLC"}},{"cell_type":"code","source":["avatar2['감상평길이'] = avatar2['영화감상평'].apply(lambda x: len(x))"],"metadata":{"id":"w3fyxKwHZfpI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["avatar2.head(10)"],"metadata":{"id":"uudmEvRV9y0L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["avatar2['영화감상평'].iloc[5]"],"metadata":{"id":"3zcX75h3brVo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 감상평길이를 기준으로 필터링\n","review = avatar2[avatar2['감상평길이'] > 10].reset_index(drop=True)"],"metadata":{"id":"Rjk78GabaJYZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["review.shape # 처음 불러온 데이터 보다 줄어듬"],"metadata":{"id":"EPX4v0subIK9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **간단한 데이터 시각화**"],"metadata":{"id":"zRJ8DY2sbNVd"}},{"cell_type":"code","source":["import seaborn as sns\n","import matplotlib.pyplot as plt\n","counts = review['영화평점'].value_counts().rename_axis('평점').reset_index(name='counts')\n","counts"],"metadata":{"id":"bVsjs6YkbI5Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["f, ax = plt.subplots(figsize = (10,6)) # x와 y의 사이즈 조정\n","ax = sns.barplot(data = counts, x='평점', y='counts', # \n","                 palette='Blues') # \n","plt.xlabel(\"평점\", fontweight='bold', fontsize = 20, labelpad = 20)\n","plt.ylabel(\"평점 개수\", fontweight='bold', fontsize = 20, labelpad = 25)\n","plt.xticks(rotation=0, fontsize=15) # rotation은 x축 눈금 문자의 각도를 조정하는 기능\n","plt.yticks(rotation=0, fontsize=15)\n","plt.tight_layout() # 그래픽을 더 compact하게 만들어주는 역할\n","plt.show()"],"metadata":{"id":"3KMLcewSh8FT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **한국어 전처리 (간소화한 버전)**"],"metadata":{"id":"HCC_3mjeykBD"}},{"cell_type":"code","source":["from konlpy.tag import Okt\n","okt = Okt()\n","text = '자연어 처리 재밌엌ㅋㅋ'\n","okt.normalize(text) # 정규화 기능을 제공, 오타가 섞인 문장의 정규화\n","# okt.phrases(text)"],"metadata":{"id":"KYh25gMDi6UF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 정규화 작업을 도와주는 함수 생성\n","def okt_normalize(x):\n","  return okt.normalize(x)"],"metadata":{"id":"yKkc9ANRzzxF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["review['정규화'] = review['영화감상평'].apply(okt_normalize)"],"metadata":{"id":"_sxqkaPXy40r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["review.head(10)"],"metadata":{"id":"OkoPuKgQz_Tp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tqdm import tqdm\n","nouns_custom = []\n","for i in tqdm(range(len(review))):\n","  nouns_custom.append(okt.nouns(review['정규화'][i]))  \n","nouns_custom[:3]"],"metadata":{"id":"v4Checdm0Smf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["review['정규화'].iloc[2]"],"metadata":{"id":"5CLbnVC31k_0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# custom한 방식으로 불용어 설정\n","stopwords = \"데 만큼 함 그 각각 관련 또한 결 관 체 위 부 및 기 층 하나 통해 관한 위한 대한 한 마련 제 이 있 하 생 용 것 들 그 되 수 이 보 않 없 나 사람 주 아니 등 같 우리 때 년 가 지 대하 오 말 일 그렇 위하 저 위한 전 난 일 걸 뭐 줄 만 건 분 개 끝 잼 이거 번 중 듯 때 게 내 말 나 수 거 점 것 의 가 이 은 들 는 좀 잘 걍 과 도 를 으로 자 에 와 하다 을 아 그 좀\"\n","stopwords = list(set(stopwords.split(\" \")))\n","print(stopwords)"],"metadata":{"id":"lj8UIuxo0sOD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 다시 새롭게 추출 \n","nouns_new = []\n","for item in nouns_custom:\n","  temp = []\n","  for element in item:\n","    if (element not in stopwords): # 불용어와 제거\n","      temp.append(element)\n","  nouns_new.append(temp)"],"metadata":{"id":"c7vvoj_E1zq7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(nouns_new[:3])"],"metadata":{"id":"N14vHGPE18sq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **단어 빈도 분석**"],"metadata":{"id":"IG9HDUbv2H5P"}},{"cell_type":"code","source":["texts = nouns_new.copy()"],"metadata":{"id":"gfCr3Ht62AOz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["texts[:3]"],"metadata":{"id":"mYh_ZWJT3QpT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["frequency_count = [element for line in texts for element in line ]\n","print(len(frequency_count))"],"metadata":{"id":"rau0L6Tv2RaR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from collections import Counter # 전체 빈도수 카운팅을 도와주는 기능\n","nouns_counter = Counter(frequency_count)\n","top_nouns = dict(nouns_counter.most_common(30)) \n","top_nouns "],"metadata":{"id":"OSl1245F2Xgs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["n =0\n","for line in texts:\n","  if \"상미\" in line:\n","    print(n)\n","  n+= 1"],"metadata":{"id":"c9UNRccH2-_c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["review['정규화'].iloc[8902]"],"metadata":{"id":"VdXHonhC3caz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **워드 클라우드**"],"metadata":{"id":"6D3F4tQ6747q"}},{"cell_type":"code","source":["from wordcloud import WordCloud\n","wc = WordCloud(background_color='white',colormap = 'seismic',\n","               font_path = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf',\n","               width = 1000, height = 800)\n","wc.generate_from_frequencies(top_nouns) "],"metadata":{"id":"jSVpOLzg2diu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(10, 10))\n","plt.imshow(wc)\n","plt.axis('off')\n","plt.tight_layout()\n","plt.savefig(\"test.png\",dpi=300)\n","plt.show()"],"metadata":{"id":"jwjSlBLr21Gn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **토픽 모델링의 적용**"],"metadata":{"id":"ZhYAFS2S4z5N"}},{"cell_type":"code","source":["from gensim import corpora # 토픽모델링\n","kr_dictionary = corpora.Dictionary(texts) # 단어들의 사전 만들기 (정수 인코딩)\n","print(kr_dictionary)"],"metadata":{"id":"HuvmJk9M23fu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 출현빈도가 적거나, 전체 문서에 걸쳐 자주 등장하는 단어는 제거 \n","kr_dictionary.filter_extremes(no_below=5, no_above=0.30)"],"metadata":{"id":"2FS_m4u86q65"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(kr_dictionary)"],"metadata":{"id":"A1FKDitd6sMX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["corpus = [kr_dictionary.doc2bow(text) for text in texts] # Term Document Frequency 만들기, 단어가 해당 문서에서 몇 번 출현하는지 여부\n","# corpus는 말뭉치를 뜻하며, 언어 표본의 집합을 의미\n","print(corpus[0]) # 수행된 결과에서 첫번째 뉴스 출력. 첫번째 문서의 인덱스는 0\n","# (단어번호, 개수)"],"metadata":{"id":"FFenub1p6Dl6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 손쉽게 읽을 수 있는 형태로 변환\n","[[(kr_dictionary[id], freq) for id, freq in cp] for cp in corpus[:1]]"],"metadata":{"id":"aMg0NjG25ArV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # texts\n","# new_list = []\n","# for line in texts:\n","#   temp = []\n","#   for element in line:\n","#     if element == \"영환\":\n","#       temp.append(\"영화\")\n","#     else:\n","#       temp.append(element)\n","#   new_list.append(temp)"],"metadata":{"id":"m_BX_OSZ5nDv"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1ZwoL706nDIP"},"outputs":[],"source":["import gensim"]},{"cell_type":"markdown","metadata":{"id":"CQQsQRMOnvY8"},"source":["num_topics : 가설로 정한 토픽의 갯수\n","\n","chunksize : 얼마나 많은 문서가 훈련 알고리즘에 사용되는지 (만약에 빠른 학습이 중요하다면, 청크사이즈를 증가) 그러나 Chunksize는 모델 품질에 영향을 미치칠 수 있음, default로 2000.\n","\n","passes : 패스는 모델 학습시 전체 코퍼스에서 모델을 학습시키는 빈도를 제어\n","\n","iteration : 각각 문서에 대해서 루프를 얼마나 돌리는지를 제어\n","\n","alpha, eta = auto, 디리클레 분포에 대한 파라미터"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qW-u_NpintPS"},"outputs":[],"source":["# LDA 모델 생성 \n","lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus, \n","                                           num_topics = 6, \n","                                           id2word=kr_dictionary,\n","                                           random_state=2000,\n","                                           passes=20,\n","                                           iterations=200\n","                                           )"]},{"cell_type":"code","source":["# 토픽별 단어를 나타냄\n","topics = lda_model.print_topics(num_words=10)\n","for topic in topics:\n","    print(topic)"],"metadata":{"id":"lmfvJaVq7ICG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tm1 = lda_model[corpus[0]] # 첫 번째 문서에는 어떤 토픽이 ?\n","tm1"],"metadata":{"id":"43GCkAee7P3_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tm2 = lda_model[corpus[1]] # 두 번째 문서에는 어떤 토픽이 ?\n","tm2"],"metadata":{"id":"vEVTnkt77Q5L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install pyLDAvis==2.1.2 "],"metadata":{"id":"3DKMseE27Wl6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pyLDAvis\n","import pyLDAvis.gensim as gensimvis\n","vis_data = gensimvis.prepare(lda_model, corpus, kr_dictionary, sort_topics=False)\n","pyLDAvis.display(vis_data)"],"metadata":{"id":"Pg8S0obA7a50"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["n_words = 10\n","\n","topic_words = pd.DataFrame({})\n","\n","for i, topic in enumerate(lda_model.get_topics()):\n","    top_feature_ids = topic.argsort()[-n_words:][::-1]\n","    feature_values = topic[top_feature_ids]\n","    words = [kr_dictionary[id] for id in top_feature_ids]\n","    topic_df = pd.DataFrame({'value': feature_values, 'word': words, 'topic': i})\n","    topic_words = pd.concat([topic_words, topic_df], ignore_index=True)"],"metadata":{"id":"aMcXo9mu7hBn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import seaborn as sns\n","import matplotlib.pyplot as plt\n","g = sns.FacetGrid(topic_words, col=\"topic\", col_wrap=3, sharey=False)\n","g.map(plt.barh, \"word\", \"value\", color='lightgray',edgecolor =\"black\")\n","plt.savefig(\"토픽.png\",dpi=300)"],"metadata":{"id":"1IBklVxn7nrD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from wordcloud import WordCloud\n","wc = WordCloud(colormap = 'seismic',\n","               font_path = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf',\n","              background_color=\"white\", max_font_size=150, random_state=42)"],"metadata":{"id":"cJfn8Iuw7o-L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["topics = [[(term, round(wt, 3)) for term, wt in lda_model.show_topic(n, topn=20)] for n in range(0, lda_model.num_topics)]\n","print(topics)"],"metadata":{"id":"olDp-bu38RkH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["topics_df2 = pd.DataFrame([', '.join([term for term, wt in topic]) for topic in topics], columns = ['Terms per Topic'],\n","                         index=['Topic'+str(t) for t in range(1, lda_model.num_topics+1)] )"],"metadata":{"id":"D5sQKUZq8ioa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(20,15))\n","# Create subplots for each topic\n","for i in range(6):\n","\n","    wc.generate(text=topics_df2[\"Terms per Topic\"][i])\n","    \n","    plt.subplot(5, 4, i+1)\n","    plt.imshow(wc, interpolation=\"bilinear\")\n","    plt.axis(\"off\")\n","    plt.title(topics_df2.index[i], fontsize=15, pad = 20)\n","\n","plt.show()"],"metadata":{"id":"DYRTN9Y17_Sp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["topic_modeling_results = lda_model[corpus]\n","results = list(topic_modeling_results)"],"metadata":{"id":"hXTqMNOu9Kv4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["corpus_topics = [sorted(topics, key=lambda record: -record[1])[0] for topics in results]"],"metadata":{"id":"KN-i9bnt9HUt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["corpus_topic_df = pd.DataFrame()\n","\n","corpus_topic_df['Dominant Topic'] = [item[0] for item in corpus_topics]\n","corpus_topic_df['Contribution %'] = [round(item[1]*100, 2) for item in corpus_topics]\n","corpus_topic_df['Topic Terms'] = [topics_df2.iloc[t[0]]['Terms per Topic'] for t in corpus_topics]"],"metadata":{"id":"xKexsaHv8lSa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dominant_topic_df = corpus_topic_df.groupby('Dominant Topic').agg(\n","                                  Doc_Count = ('Dominant Topic', np.size),\n","                                  Total_Docs_Perc = ('Dominant Topic', np.size)).reset_index()\n","\n","dominant_topic_df['Total_Docs_Perc'] = dominant_topic_df['Total_Docs_Perc'].apply(lambda row: round((row*100) / len(corpus), 2))\n","\n","dominant_topic_df"],"metadata":{"id":"Y2EvgzL9-QI_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **토픽의 개수 설정**"],"metadata":{"id":"QkIAmMqk-w5_"}},{"cell_type":"code","source":["import warnings \n","warnings.filterwarnings('ignore')"],"metadata":{"id":"2XMVb--a-8lP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**시간이 상당히 소요될 수 있는 작업**"],"metadata":{"id":"720Py8Xr-_dF"}},{"cell_type":"code","source":["from gensim.models import CoherenceModel\n","coherence_values = []\n","perplexities=[] # 낮을 수록 더 좋은 값\n","model_list = []\n","for i in range(2,21):\n","  ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = i, id2word=kr_dictionary, passes=10,random_state=2000, iterations=100)\n","  model_list.append(ldamodel)\n","  coherencemodel = CoherenceModel(model=ldamodel, texts=texts, dictionary=kr_dictionary, coherence='c_v')\n","  coherence_values.append(coherencemodel.get_coherence())\n","  perplexities.append(ldamodel.log_perplexity(corpus))"],"metadata":{"id":"cypnmi5N-0Ro"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","ind = np.argmax(coherence_values)\n","print(ind)"],"metadata":{"id":"STwbMaPDCfSH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x = range(2, 21, 1)\n","plt.plot(x, coherence_values)\n","plt.xlabel(\"Num Topics\")\n","plt.ylabel(\"Coherence score\")\n","plt.xticks([2,4,6,8,10,12,14,16,18,20])\n","plt.legend((\"Coherence\"), loc='best')\n","plt.show()"],"metadata":{"id":"n8AUwN6w-3dk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **새로운 문서의 토픽 할당**"],"metadata":{"id":"ZMjmIGrwAcko"}},{"cell_type":"code","source":["# 훈련에 사용된 corpus가 아닌 새로운 document에 대해 토픽 모델링을 수행할 수 있으나\n","# 정확도는 다소 떨어질 수 있다.\n","def doc_to_bow(doc): #\n","    token = okt.nouns(doc) # 명사만 추출\n","    temporary = []\n","    for t in token:\n","      if t not in stopwords:\n","        temporary.append(t)\n","    bow = kr_dictionary.doc2bow(temporary)\n","    return bow"],"metadata":{"id":"RY42eyexAf1m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result = model_list[3][(doc_to_bow('스토리가 너무 뻔하지만 재미있었어요'))]\n","print(result)"],"metadata":{"id":"ADJ8kaCYCG4p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result = model_list[3][(doc_to_bow('넷플릭스에서 보고싶다'))] # 전혀 상관없는 문장의 경우,균등하게 나눈 토픽으로 판단\n","print(result)"],"metadata":{"id":"WKs9ulRZCLa_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"xLTbmuzPCQ1H"},"execution_count":null,"outputs":[]}]}